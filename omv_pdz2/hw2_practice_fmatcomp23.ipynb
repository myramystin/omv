{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZELSweDvTyN6"
   },
   "source": [
    "# Практическое ДЗ-2. Использование ALS для построения рекомендательной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf0VwGfTTyN6"
   },
   "source": [
    "В этой задаче мы построим простую рекомендательную модель на основе малоранговых приближений. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Fhwokt4cTyN7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJ3WCOxFTyN_"
   },
   "source": [
    "### Подготовка датасета\n",
    "Загрузите датасет movielens10m с [grouplens.org](https://grouplens.org/datasets/movielens/10m/) или [disk.yandex.ru](https://disk.yandex.ru/d/HIjLehGZEcCRig) и положите архив в папку `data`. Нас будет интересовать файл `ratings.dat`, в котором собраны оценки пользователями различных фильмов с сервиса movielens.org. Вытащим этот файл из архива. Как можно узнать из соответствующей [странички](http://files.grouplens.org/datasets/movielens/ml-10m-README.html#file_desc), этот файл имеет формат `UserID::MovieID::Rating::Timestamp`. Сразу позаботимся, чтобы id пользователей и фильмов начинались с нуля (в самом файле индексация с единицы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "id": "JJJ8tRX-TyN_"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "user_ids = []\n",
    "movie_ids = []\n",
    "ratings = []\n",
    "with zipfile.ZipFile('data/ml-10m.zip') as archive:\n",
    "    with archive.open('ml-10M100K/ratings.dat') as f:\n",
    "        for l in f:\n",
    "            user, movie, rating, _ = l.split(b'::')\n",
    "            user_ids.append(int(user) - 1)\n",
    "            movie_ids.append(int(movie) - 1)\n",
    "            ratings.append(float(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcVcCOT8TyOA"
   },
   "source": [
    "Составим матрицу рейтингов $A \\in \\mathbb R^{m \\times n}$, индексируемую номером пользователем и номером фильма.\n",
    "Для простоты мы будем делить отзывы только на положительные (`Rating >= 4` &mdash; $A_{i,j}=1$) и отрицательные (`Rating < 4` &mdash; $A_{i,j} = 0$), таким образом, матрица у нас получится состоящей только из нулей и единиц.\n",
    "Обратите внимание, что матрица будет разреженной, так как средний пользователь оценил относительно мало фильмов. Поэтому мы будем пользоваться библиотекой `scipy.sparse`. Хранить матрицу мы будем в формате хранения разреженных матриц [CSR](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)), который поддерживает матричное умножение на numpy массивы: ```A @ X ```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "id": "Via3f58zTyOA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (71567, 65133)\n",
      "Ratio of nonzero elements: 0.0010738646228571796\n",
      "Shape: (71567, 65133)\n",
      "Ratio of nonzero elements: 0.0010738646228571796\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "A = csr_matrix((np.array(ratings) >= 4, (user_ids, movie_ids)), dtype=np.float32)\n",
    "A.eliminate_zeros()\n",
    "print(\"Shape:\", A.shape)\n",
    "print(\"Ratio of nonzero elements:\", A.nnz / (A.shape[0] * A.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7IH4xmRTyOB"
   },
   "source": [
    "Отделим некоторое количество пользователей для последующей проверки. Используем стандартное разбиение train/test 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hkVwyh5BTyOB"
   },
   "outputs": [],
   "source": [
    "n_users, n_movies = A.shape\n",
    "n_test = int(n_users * 0.2)\n",
    "n_train = n_users - n_test\n",
    "idx = np.arange(n_users)\n",
    "np.random.shuffle(idx)\n",
    "test_idx, train_idx = idx[:n_test], idx[n_test:]\n",
    "A_test, A_train = A[test_idx,:], A[train_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Далее в задаче мы будем строить рекомендации пользователям на основе малорангового приближения матрицы $A$ (матрицы $A_{train}$ в рамках обозначений выше). \n",
    "Обратим внимание, что из-за ограничений по памяти мы не можем сформировать матрицу $A$ в виде numpy массива, а значит теряем доступ к ```np.linalg.svd```. Поэтому мы будем реализовывать метод ALS, в котором требуется только умножение на матрицы $A$ и $A^\\top$, что поддерживается разреженными форматами хранения матриц (CSR, COO и тд).\n",
    "\n",
    "### a. (35 баллов) Вычисление вспомогательных функционалов\n",
    "\n",
    "  1. **(15 баллов)** Напомним, что в методе ALS решается задача минимизации функционала $f(U, V^\\top) = \\|A - UV^\\top\\|_F$ по всем $U \\in \\mathbb R^{m \\times r}$ и $V  \\in \\mathbb R^{n \\times r}$. Первым делом вам нужно будет написать функцию `als_functional` для вычисления оптимизируемого функционала $\\|A - UV^\\top\\|_F$ для заданных $A$, $U$, $V^\\top$. Заметьте, что прямое вычисление этой нормы &mdash; очень трудоёмкая задача, ведь разность будет плотной матрицей. Для того, чтобы эффективно вычислить норму разности, распишите $\\|A - UV^\\top\\|_F^2$ через скалярное произведение $\\langle X,Y \\rangle_F = \\mathrm{Tr}\\,(X^\\top Y)$, выполните алгебраические преобразования и покажите, как эффективно вычислить каждый член в полученном выражении. Имеется в виду, что ни на каком этапе вы не должны явно формировать плотные матрицы размеров `A.shape` (хотя numpy, скорее всего, и откажется аллоцировать 37 ГБ под такой массив).\n",
    "  \n",
    "  **Замечание**: не используйте циклы по ненулевым элементам разреженной матрицы $A$. Убедитесь, что в ваши формулы входит только умножение на матрицы $A$ или $A^\\top$, на которые можно умножать посредством @; либо умножения сложности $O(mr^2), O(nr^2)$. Также отметим, что норма матрицы $A$ уже дана, заново её вычислять не надо. Везде считайте $r < m, n$."
   ],
   "metadata": {
    "id": "1yD1HCUByDHB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\|A - UV^\\top\\|^2_F = \\langle A - UV^\\top, A - UV^\\top \\rangle = Tr((A - UV^\\top)^\\top (A - UV^\\top)) =\n",
    "Tr(A^TA) - Tr(VU^TA) - Tr(A^TUV^T) + Tr(VU^TUV^T) =\n",
    "\\|A\\|^2_F - 2Tr(V^TA^T)U) + Tr(V^TVU^TU)\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U9ZqSC1_TyOC"
   },
   "outputs": [],
   "source": [
    "def als_functional(A, A_norm, U, VT):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A: sparse 2D array\n",
    "            A_norm: Frobenius norm of A\n",
    "            U, VT: 2D arrays such that U @ VT approximates A\n",
    "        Output\n",
    "            ||A - U VT||_F\n",
    "    \"\"\"\n",
    "    sq = A_norm**2 - 2*np.trace((VT @ A.T) @ U) + np.trace((VT @ VT.T) @ (U.T @ U))\n",
    "    return np.sqrt(sq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: 2.6147972675971687e-12\n"
     ]
    }
   ],
   "source": [
    "m, n = (1000, 500)\n",
    "r = 100\n",
    "\n",
    "A = np.random.randn(m, n)\n",
    "A_norm = np.linalg.norm(A)\n",
    "Q, R = np.linalg.qr(A)\n",
    "Q, R = Q[:, :r], R[:r, :]\n",
    "print(\"diff:\", np.linalg.norm(A - Q@R) - als_functional(A, A_norm, Q, R))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.08 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "8.4 ms ± 4.65 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.linalg.norm(A - Q@R)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.36 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "5.74 ms ± 4.49 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit als_functional(A, A_norm, Q, R)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Замечание:** Если вы не сможете выполнить следующие два пункта, можете их пропустить. Они не являются обязательными для следующих заданий."
   ],
   "metadata": {
    "id": "NqrSPQn0LR4H"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5GU38ZfTyOD"
   },
   "source": [
    "  2. **(10 баллов)** Ещё одной метрикой сходимости ALS-процесса, помимо стабилизации самого функционала, может служить так называемое расстояние между подпространствами. Расстоянием между подпространствами $L_1 \\subset \\mathbb{R}^m$ и $L_2 \\subset \\mathbb{R}^m$ будем называть число $\\|P(L_1) - P(L_2)\\|_2$, где $P(L_i)$ &mdash; ортопроектор на $L_i$. Опишите алгоритм вычисления расстояния между двумя подпространствами $\\mathrm{Im}(U_1)$ и $\\mathrm{Im}(U_2)$ для заданных матриц $U_1, U_2 \\in \\mathbb{R}^{m \\times r}$ с ортонормированными столбцами (т.е. $U_i^T U_i = I$). Алгоритм должен иметь сложность $O(mr^2)$. **Подсказка.** Воспользуйтесь фактом, что ортопроекторы являются матрицами малого ранга $r$, и техникой малоранговой арифметики, описанной на соответствующих лекции и семинаре."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7Fxh5EDTyOD"
   },
   "source": [
    "**YOUR WORDS GO HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjH9NjfATyOD"
   },
   "source": [
    "  3. **(10 баллов)** Напишите функцию `dist_between_subspaces`, принимающую на вход матрицы $U_1, U_2 \\in \\mathbb{R}^{m\\times r}$ с ортонормированными столбцами, и возвращающую расстояние от $\\mathrm{Im}(U_1)$ до $\\mathrm{Im}(U_2)$. Сложность алгоритма должна быть $O(mr^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiBRvfriTyOD"
   },
   "outputs": [],
   "source": [
    "def dist_between_subspaces(U1, U2):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            U1, U2: matrices with orthonormal columns\n",
    "        Output\n",
    "            Distance between Im(U1) and Im(U2)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzuzjg7qTyOE"
   },
   "source": [
    "### b. (30 баллов) Метод ALS\n",
    "Реализуйте метод ALS (alternating least squares) с ортогонализацией (см. лекции).\n",
    "\n",
    "Вам будет необходимо вернуть две матрицы: $U$ и $V^\\top$, образующие скелетное разложение результирующего приближения; где $U$ имеет ортонормированные столбцы. Также нужно вернуть 3 списка:\n",
    "\n",
    "\n",
    "*   Список значений функционала $f(U_k, V^\\top_k) = \\|A - U_k V^\\top_k\\|_F$\n",
    "\n",
    "*   Список изменений значений функционала $\\delta_k = f(U_{k-1}, V^\\top_{k-1}) - f(U_k, V^\\top_k)$\n",
    "\n",
    "*   Список растояний между пространствами $\\|P(U_{k-1}) - P(U_{k})\\|_2$\n",
    "\n",
    "В качестве критерия остановки будем использовать величину $\\delta_k$. При значении $\\delta_k \\le tolerance$ алгоритм должен остановиться. При указании `debug=True` печатайте номер текущей итерации и последнюю $\\delta_k$, а также любую дополнительную интересную вам информацию. \n",
    "\n",
    "Используйте реализованные выше функции. Для вычисления фробениусовой нормы разреженной матрицы используйте `norm` из `scipy.sparse.linalg`.\n",
    "\n",
    "**Замечание:** Если вы не реализовали dist_between_subspaces, то вместо третьего списка возращайте None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syRWnqliTyOE"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import norm as sparse_norm\n",
    "\n",
    "def ALS(A, rank, tolerance=1e-2, debug=False):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A: 2D m x n numpy array\n",
    "            rank: required rank of the approximation\n",
    "            tolerance: stop when delta_k is less or equal to it\n",
    "            debug: print debug information on each iteration\n",
    "            \n",
    "        Output\n",
    "            U, VT: m x rank, rank x n numpy arrays forming skeleton decomposition;\n",
    "                   columns of matrix U are orthonormal\n",
    "            fs: list of f(U_k, VT_k)\n",
    "            deltas: list of f(U_{k-1}, VT_{k-1}) - f(U_k, VT_k)\n",
    "            dists: list of distances between Im(U_{k-1}) and Im(U_k)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6dYV_Y0TyOE"
   },
   "source": [
    "Запустим метод на матрице `A_train` и посмотрим на убывание расстояния между соседними подпространствами от номера итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jOy0WGPTyOE"
   },
   "outputs": [],
   "source": [
    "rank = 30\n",
    "U_als, VT_als, fs, deltas, dists = ALS(A_train, rank, 0.1, debug=True)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12, 5), ncols=2)\n",
    "\n",
    "axs[0].plot(fs)\n",
    "axs[1].plot(deltas)\n",
    "axs[1].semilogy();"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# если выполнили a.3\n",
    "\n",
    "plt.plot(dists);"
   ],
   "metadata": {
    "id": "SjD9StBsZmn2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbvYe-FlTyOF"
   },
   "source": [
    "### c. (10 баллов) Сравнение с рандомизированным SVD и разреженным SVD\n",
    "\n",
    "Примените рандомизированное SVD из sklearn, а также SVD из scipy, поддерживающее разреженные матрицы (используйте тот же ранг 30, что и для ALS). Сравните все три результата по значению функционала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8XbjL63TyOF"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "A_norm = sparse_norm(A_train)\n",
    "\n",
    "# TO BE FILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKZ40jk8TyOF"
   },
   "source": [
    "## d. (25 баллов) Построение рекомендаций\n",
    "  1. **(10 баллов)** Научимся рекомендовать пользователям из тестовой группы фильмы на основе части их оценок. Напишем функцию `recommend`, которая будет принимать матрицу $V^\\top$ из нашей модели, матрицу `(user_id, movie_id) -> binary rating` (то есть того же формата, что и наша основная матрица `A`), а также число `n_recs` &mdash; количество фильмов, которые мы хотим порекомендовать. Возвращать функция будет top-`n_recs` рекомендаций, то есть `n_recs` фильмов, которые могут пользователю понравиться, в порядке убывания предсказанной привлекательности.\n",
    "\n",
    "  Чтобы построить рекомендацию, необходимо ортогонально спроецировать вектор, соответствующий новому пользователю (про которого мы знаем часть оценок), на пространство $L$, образуемое строками матрицы $V^\\top$. Иными словами, мы должны взять ближайший вектор из $L$. Он будет содержать предсказанные нашей моделью рейтинги. Дальше дело техники :) Но не забудьте, что `known_ratings` содержит векторы, соответствующие не одному пользователю, а батчу из `batch_size` пользователей. Хотя и (слава numpy) код остаётся почти дословно такой же.  **Подсказка:** используйте функцию `np.argsort`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Q3lIQY7TyOG"
   },
   "outputs": [],
   "source": [
    "def recommend(VT, known_ratings, n_recs):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            VT: 2D numpy array\n",
    "            known_rating: sparse batch_size x n_movies array\n",
    "            n_recs: requested number of recommendations\n",
    "            \n",
    "        Output\n",
    "            recs: batch_size x n_recs array of movies to recommend, with descending predicted rating\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9Ub94g2TyOG"
   },
   "source": [
    "Для проверки нашей модели для каждого пользователя из тестовой выборки оценим так называемый **hit rate**. Для этого выбросим одну из его оценок, вызовем функцию `recommend` и посмотрим, попал ли выкинутый фильм в подборку. Если попал &mdash; это hit, иначе не hit. Для того, чтобы эффективно проделать этот эксперимент на всех тестовых данных, сделаем следующее: разобьём тестовую матрицу на батчи по 500 пользователей и будем предсказывать сразу для целого батча. Вычислим вектор размера `n_test`, где для каждого пользователя указано, на каком месте в рекомендованной подборке оказался скрытый фильм (или число `n_recs`, если скрытого фильма не нашлось среди top-n  рекомендаций)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJV-DwZOTyOG"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "\n",
    "def evaluate_model(VT, A_test, n_recs, batch_size=500):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            VT: 2D numpy array representing the rating model\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users\n",
    "            n_recs: requested number of recommendations\n",
    "            batch_size: number of users to build recommendations for in a single call to recommend\n",
    "\n",
    "        Output\n",
    "            hit_idx: list of n_test ints: place of secret movie \n",
    "                     in top-n_recs recommendations (or n_recs if it is missing)\n",
    "    \"\"\"\n",
    "    secrets = []\n",
    "    nonempty_users = []\n",
    "    A_test = A_test.copy()\n",
    "    for user in range(A_test.shape[0]):\n",
    "        _, good, _ = find(A_test[user,:])\n",
    "        if len(good) == 0:\n",
    "            continue\n",
    "        nonempty_users.append(user)\n",
    "        secret = np.random.choice(good, 1)[0]\n",
    "        A_test[user, secret] = 0\n",
    "        secrets.append(secret)\n",
    "    hit_idx = []\n",
    "    for i in range(0, len(nonempty_users), batch_size):\n",
    "        # Build recomendations for a batch.\n",
    "        recommendations = recommend(VT, A_test[nonempty_users[i:i + batch_size], :], n_recs + 1)\n",
    "        # Place secret in the last column so that the following .argmax finds it.\n",
    "        recommendations[:,-1] = secrets[i: i + batch_size]\n",
    "        # Find secret among the recommendations and place its index into batch_hit_idx.\n",
    "        batch_hit_idx = (recommendations == np.array([secrets[i:i + batch_size]]).T).argmax(1)\n",
    "        hit_idx += batch_hit_idx.tolist()\n",
    "    return hit_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTSTcoZyTyOG"
   },
   "source": [
    "  2. **(15 баллов)** Научимся вычислять hit rate для данной модели и заданного количества top-n рекомендаций. Для этого напишем функцию `get_hit_rates`, которая будет принимать $V^\\top$ из нашей модели, вектора оценок для новых пользователей `A_test` и список натуральных чисел `n_recs`. Для каждого из этих чисел необходимо посчитать средний hit rate по всем пользователям из `A_test`, то есть, например, для `n_recs == [5, 10, 20]` нужно вернуть список средних хитрейтов для top-5, top-10 и top-20. **Обратите внимание:** вызвать функцию `evaluate_model` нужно только один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjpcCThdTyOH"
   },
   "outputs": [],
   "source": [
    "def get_hit_rates(VT, A_test, n_recs):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            VT: 2D numpy array representing the rating model\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users \n",
    "            n_recs: list of ints: number of top recomendations to evaluate hit rate for\n",
    "        Output\n",
    "            hit_rates: list of float: hit rate for each element of n_recs\n",
    "    \n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYXL52ivTyOH"
   },
   "source": [
    "Проверьте себя: вычислите хитрейт на top-10 рекомендаций для Sparse SVD ранга 30. Чтобы вычисления рекомендаций были побыстрее, используйте не всю матрицу `A_test`, а, например, первые 1000 строк. Хитрейт должен получится в районе 12-15%. Самое время подебажить своё решение, если числа сильно расходятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDg20id6TyOH"
   },
   "outputs": [],
   "source": [
    "# TO BE FILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA5GzyK3TyOH"
   },
   "source": [
    "Теперь можно построить графики зависимости hit rate от количества рекомендаций, а также от ранга модели. Сравним результаты, которые дают три алгоритма: ALS, Sparse SVD и рандомизированный SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgWOKFW1TyOH"
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "n_recs = list(range(5, 101, 5))\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "_, (ax_svd, ax_als, ax_rand) = plt.subplots(1,3,figsize=(20, 4),sharey=True)\n",
    "\n",
    "ax_svd.set_title(\"SVD\")\n",
    "ax_svd.set_ylabel(\"Hit rate\")\n",
    "ax_als.set_title(\"ALS\")\n",
    "ax_rand.set_title(\"Rand SVD\")\n",
    "for rank in [5, 25, 50]:\n",
    "    _, _, VT_svd = svds(A_train, k=rank)\n",
    "    _, VT_als, _, _, _ = ALS(A_train, rank)\n",
    "    _, _, VT_rand = randomized_svd(A_train, rank)\n",
    "    for VT, ax in zip([VT_svd, VT_als, VT_rand], [ax_svd, ax_als, ax_rand]):\n",
    "        ax.set_xlabel(\"Number of recomendations\")\n",
    "        hit_rates = get_hit_rates(VT, A_test[:1000,:], n_recs)\n",
    "        line, = ax.plot(n_recs, hit_rates)\n",
    "        line.set_label('rank = {}'.format(rank))\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXwiSVujTyOH"
   },
   "source": [
    "Какой ранг приближения оказался оптимальным для нашей модели в случае каждого алгоритма?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**YOUR WORDS GO HERE**"
   ],
   "metadata": {
    "id": "4u_qcZU_8e_q"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckrRNR8FTyOI"
   },
   "source": [
    "## Бонус. Higher-order SVD (100 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**В бонусе разрешается использовать циклы только по размерности.**"
   ],
   "metadata": {
    "id": "F4CTYLs114Kw"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEv9r59gTyOI"
   },
   "source": [
    "1. (**20 баллов**) Напишите функцию ```tuck2full(G, Us)```, возвращающую полный тензор размера $n_1\\times n_2 \\times \\ldots \\times n_d$ по его разложению Таккера. Предусмотрите, чтобы функция работала и в случае, если в матрицах $U_1,U_2, \\ldots, U_d$ строк меньше, чем столбцов. Вместо циклов используйте функцию ```np.einsum```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkoj_t3LTyOI"
   },
   "outputs": [],
   "source": [
    "def tuck2full(G, Us):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            G: d-dimensional numpy array - Tucker core of size (r1, r2, ..., rd)\n",
    "            Us: tuple of 2D numpy arrays - Tucker factors of size (n1, r1), ..., (nd, rd)\n",
    "\n",
    "        Output\n",
    "            A: d-dimensional numpy array of the size (n1, n2, ..., nd)\n",
    "    \"\"\"\n",
    "    # TO BE FILLED\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miBsDExrTyOI"
   },
   "source": [
    "2. (**35 баллов**) Реализуйте higher-order SVD алгоритм для нахождения разложения Таккера данного $d$-мерного массива $A\\in\\mathbb{R}^{n_1\\times \\ldots \\times n_d}$. Алгоритм должен находить малоранговое приближение $A$ с относительной точностью не хуже $\\varepsilon$ во Фробениусовой норме. Функция должна вернуть ядро и факторы Таккера у приближающего тензора. Для получения ядра Таккера будет удобно воспользоваться функцией ```tuck2full```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hgVftQgTyOI"
   },
   "outputs": [],
   "source": [
    "def hosvd(A, eps):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A: 3D numpy array\n",
    "            eps: accuracy of Tucker approximation\n",
    "\n",
    "        Output\n",
    "            G: d-dimensional numpy array - Tucker core of size (r1, r2, ..., rd)\n",
    "            Us: tuple of 2D numpy arrays - Tucker factors of size (n1, r1), ..., (nd, rd)\n",
    "    \"\"\"\n",
    "    # TO BE FILLED\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKuGY2KdTyOI"
   },
   "source": [
    "3. (**5 баллов**) Примените функцию ```hosvd``` к тензору размера $25 \\times 50 \\times 75 \\times 100$ с элементами\n",
    "$$\n",
    "    a_{ijkl} = \\frac{1}{i + j + k + l + 1}, \\quad i,j,k,l=0,1,...\n",
    "$$\n",
    "для малорангового приближения с точностью $10^{-6}$. Массив $A$ соберите с помощью функции ```np.meshgrid```. Напечатайте получившиеся ранги и относительную ошибку полученного малорангового приближения (для этого используйте функцию ```tuck2full```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjfs3z8gTyOJ"
   },
   "outputs": [],
   "source": [
    "# TO BE FILLED"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. (**15 баллов**) Докажите, что норма Фробениуса приближения HOSVD $A'$ совпадает с её ядром Таккера $G'$:\n",
    "\n",
    "$$\n",
    "  \\|A'\\|_F = \\|G'\\|_F\n",
    "$$"
   ],
   "metadata": {
    "id": "6ws5NBZk2Bbq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**YOUR WORDS GO HERE**"
   ],
   "metadata": {
    "id": "5ROu4qdE2E2T"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. (**25 баллов**) Для заданного таккеровского разложения напишите функцию вычисления его нормы. Примените ее к разложению тензора размера 10000 x 10000 x 10000 со случайными Таккеровскими факторами и ядром мультилинейного ранга (10, 10, 10)."
   ],
   "metadata": {
    "id": "1kJsjUll2Cvz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def tuck_norm(G, Us):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            G: d-dimensional numpy array - Tucker core of size (r1, r2, ..., rd)\n",
    "            Us: tuple of 2D numpy arrays - Tucker factors of size (n1, r1), ..., (nd, rd)\n",
    "\n",
    "        Output\n",
    "            norm: Frobenius norm of A = [G; U1 ... Ud]\n",
    "    \"\"\"\n",
    "    # TO BE FILLED\n",
    "    raise NotImplementedError()"
   ],
   "metadata": {
    "id": "7TtsdZKs1_Gs"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
